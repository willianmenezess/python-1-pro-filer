# Project ProFiler - Eletiva Back-end com Python

RepositÃ³rio do projeto ProFiler.
  
<details>
<summary><strong>ğŸ§‘â€ğŸ’» O que deverÃ¡ ser desenvolvido</strong></summary>

VocÃª irÃ¡ trabalhar com uma aplicaÃ§Ã£o com uma interface de linha de comando (CLI) que recebe como entrada um caminho (diretÃ³rio ou arquivo) e gera um relatÃ³rio com informaÃ§Ãµes sobre o caminho informado.

Para executar a aplicaÃ§Ã£o:

1. Siga os passos do tÃ³pico [**ğŸ•ï¸ Ambiente Virtual**]
2. Configure o auto-complete da aplicaÃ§Ã£o com o comando `pro-filer --install-completion` e reinicie o terminal;
3. Execute o comando `pro-filer` seguido de um caminho (diretÃ³rio ou arquivo) e uma aÃ§Ã£o. Por exemplo:

```bash
pro-filer . preview
```

![pro-filer preview](./images/pro-filer-preview.gif)

A aplicaÃ§Ã£o jÃ¡ estÃ¡ funcional, mas possui dois problemas:

1. alguns bugs precisam ser corrigidos;
2. mais testes precisam ser implementados.

VocÃª deverÃ¡ corrigir os bugs e implementar os testes para garantir que a aplicaÃ§Ã£o funcione corretamente. SerÃ¡ o momento de aplicar tudo o que vocÃª aprendeu sobre debugging e testes automatizados em Python!

</details>
  
<details>
  <summary><strong>:memo: Habilidades a serem trabalhadas </strong></summary>

Neste projeto, verificamos se vocÃª Ã© capaz de:

- Encontrar bugs no cÃ³digo de uma aplicaÃ§Ã£o escrita em Python;
- Corrigir bugs no cÃ³digo de uma aplicaÃ§Ã£o escrita em Python;
- Criar testes para uma aplicaÃ§Ã£o escrita em Python;
- Utilizar o `pytest` para criar testes automatizados em uma aplicaÃ§Ã£o escrita em Python.

<!-- ğŸ¤” [HS] Escrevam as habilidade utilizando a Taxonomia de Bloom. -->

</details>

<details>
<summary><strong>â€¼ Antes de comeÃ§ar a desenvolver</strong></summary>

<!-- ğŸ¤” [HS] Aqui, deve-se adicionar os comandos mais utilizados e orientaÃ§Ãµes de como preparar o repositÃ³rio. Atualize o nome do repositÃ³rio do projeto nas instruÃ§Ãµes a seguir -->

1. Clone o repositÃ³rio

- Use o comando: `git clone git@github.com:tryber/python-029-python-projeto-pro-filer.git`
- Entre na pasta do repositÃ³rio que vocÃª acabou de clonar:
  - `cd python-029-python-projeto-pro-filer`

2. Instale as dependÃªncias

    - Siga os passos do tÃ³pico [**ğŸ•ï¸ Ambiente Virtual**]

3. Crie uma branch a partir da branch `main`

- Verifique que vocÃª estÃ¡ na branch `main`
  - Exemplo: `git branch`
- Se vocÃª nÃ£o estiver, mude para a branch `main`
  - Exemplo: `git checkout main`
- Agora, crie uma branch Ã  qual vocÃª vai submeter os `commits` do seu projeto:
  - VocÃª deve criar uma branch no seguinte formato: `nome-sobrenome-nome-do-projeto`;
  - Exemplo: `git checkout -b maria-soares-pro-filer`

4. Crie na raiz do projeto os arquivos que vocÃª precisarÃ¡ desenvolver:

- Verifique que vocÃª estÃ¡ na raiz do projeto:
  - Exemplo: `pwd` -> o retorno vai ser algo tipo _/Users/maria/code/**python-029-python-projeto-pro-filer**_
- Crie ou edite algum arquivo necessÃ¡rio ao projeto

5. Adicione as mudanÃ§as ao _stage_ do Git e faÃ§a um `commit`

- Verifique que as mudanÃ§as ainda nÃ£o estÃ£o no _stage_:
  - Exemplo: `git status` (devem aparecer listados os novos arquivos em vermelho)
- Adicione o novo arquivo ao _stage_ do Git:
  - Exemplo:
    - `git add .` (adicionando todas as mudanÃ§as - _que estavam em vermelho_ - ao stage do Git)
    - `git status` (devem aparecer listados os arquivos em verde)
- FaÃ§a o `commit` inicial:
  - Exemplo:
    - `git commit -m 'iniciando o projeto. VAMOS COM TUDO :rocket:'` (fazendo o primeiro commit)
    - `git status` (deve aparecer uma mensagem tipo _nothing to commit_ )

6. Adicione a sua branch com o novo `commit` ao repositÃ³rio remoto

- Usando o exemplo anterior: `git push -u origin maria-soares-pro-filer`

7. Crie um novo `Pull Request` _(PR)_

- VÃ¡ atÃ© a pÃ¡gina de _Pull Requests_ do repositÃ³rio no GitHub em `<url_do_repositÃ³rio>/pulls`:
  - Clique no botÃ£o verde _"New pull request"_
  - Clique na caixa de seleÃ§Ã£o _"Compare"_ e escolha a sua branch **com atenÃ§Ã£o**
- Coloque um tÃ­tulo para o seu _Pull Request_
  - Exemplo: _"Cria tela de busca"_
- Clique no botÃ£o verde _"Create pull request"_

- Adicione uma descriÃ§Ã£o para o _Pull Request_, um tÃ­tulo nÃ­tido que o identifique, e clique no botÃ£o verde _"Create pull request"_

 <img width="1335" alt="Exemplo de pull request" src="https://user-images.githubusercontent.com/42356399/166255109-b95e6eb4-2503-45e5-8fb3-cf7caa0436e5.png">

- Volte atÃ© a pÃ¡gina de _Pull Requests_ do repositÃ³rio no GitHub em `<url_do_repositÃ³rio>/pulls` e confira que o seu _Pull Request_ estÃ¡ criado

</details>

<details>
  <summary><strong>ğŸ•ï¸ Ambiente Virtual</strong></summary>
  O Python oferece um recurso chamado de ambiente virtual, onde permite sua mÃ¡quina rodar sem conflitos, diferentes tipos de projetos com diferentes versÃµes de bibliotecas.

  1. **criar o ambiente virtual**

  ```bash
  python3 -m venv .venv
  ```

  2. **ativar o ambiente virtual**

  ```bash
  source .venv/bin/activate
  ```

  3. **instalar as dependÃªncias no ambiente virtual**

  ```bash
  python3 -m pip install -r dev-requirements.txt
  ```

  Com o seu ambiente virtual ativo, as dependÃªncias serÃ£o instaladas neste ambiente.
  Quando precisar desativar o ambiente virtual, execute o comando `deactivate`. Lembre-se de ativar novamente quando voltar a trabalhar no projeto.

  O arquivo `dev-requirements.txt` instalarÃ¡ todas as dependÃªncias que serÃ£o utilizadas no projeto, ele estÃ¡ agindo como se fosse um `package.json` de um projeto `Node.js`. Se vocÃª desejar instalar uma nova dependÃªncia, basta adicionÃ¡-la no arquivo `dev-requirements.txt` e executar o comando `python3 -m pip install -r dev-requirements.txt` novamente.

  Se o VS Code nÃ£o reconhecer as dependÃªncias instaladas no ambiente virtual criado, serÃ¡ necessÃ¡rio informar o caminho do interpretador Python. Para isso, abra o VS Code e pressione `Ctrl + Shift + P` (no Mac, `Cmd + Shift + P`) e digite `Python: Select Interpreter`. Selecione o interpretador que possui o caminho `./.venv/bin/python` no nome.
</details>

<details>
<summary><strong>ğŸ› Linter</strong></summary>

Para garantir a qualidade do cÃ³digo, vamos utilizar nesse projeto o linter `Flake8`. Assim o cÃ³digo estarÃ¡ alinhado com as boas prÃ¡ticas de desenvolvimento, sendo mais legÃ­vel e de fÃ¡cil manutenÃ§Ã£o! Para poder executar o `Flake8`, certifique-se de ter seguido os passos do tÃ³pico [**ğŸ•ï¸ Ambiente Virtual**] dentro do repositÃ³rio.

Para rodÃ¡-lo localmente no repositÃ³rio, execute o comando a seguir:

```bash
python3 -m flake8
```

Se a anÃ¡lise do `Flake8` encontrar problemas no seu cÃ³digo, tais problemas serÃ£o mostrados no seu terminal. Se nÃ£o houver problema no seu cÃ³digo, nada serÃ¡ impresso no seu terminal.

</details>

<details>
  <summary><strong>ğŸ›  Testes</strong></summary>

  Para executar os testes certifique-se de que vocÃª estÃ¡ com o ambiente virtual ativado.

  <strong>Executar os testes</strong>

  ```bash
  python3 -m pytest
  ```

  O arquivo `pyproject.toml` jÃ¡ configura corretamente o `pytest`. Entretanto, caso vocÃª tenha problemas com isso e queira explicitamente uma saÃ­da completa, o comando Ã©:

  ```bash
  python3 -m pytest -s -vv --continue-on-collection-errors
  ```

  O `pytest` possui diversos parÃ¢metros que podem ser utilizados para executar os testes de diferentes formas. Alguns exemplos sÃ£o:

  ```bash
  python3 -m pytest tests/test_nome_do_arquivo.py  # Executa todos os testes do arquivo de testes especificado
  python3 -m pytest tests/test_nome_do_arquivo.py::test_nome_do_teste  # Executa apenas o teste especificado
  python3 -m pytest -k expressao  # Executa apenas os testes que contÃ©m a expressÃ£o informada como substring
  python3 -m pytest -x  # Executa os testes atÃ© encontrar o primeiro erro
  ```

  VocÃª pode combinar os parÃ¢metros para executar os testes da forma que desejar! Para mais informaÃ§Ãµes, consulte a [documentaÃ§Ã£o do pytest](https://docs.pytest.org/en/7.3.x/contents.html).
</details>

## Requisitos do projeto

### 1. Elimine o(s) bug(s) da funÃ§Ã£o `show_deepest_file`

> Arquivo a ser alterado: `pro_filer/actions/beta_actions.py`

VocÃª estÃ¡ colaborando com a comunidade open-source e recebeu uma tarefa de corrigir bugs em algumas funÃ§Ãµes!

Encontre e corrija o(s) bug(s) da funÃ§Ã£o `show_deepest_file` para que ela informe corretamente o caminho arquivo mais profundo dentro do diretÃ³rio informado.

Execute os testes do arquivo `tests/actions/test_deepest_file.py` para te ajudar a encontrar o(s) bug(s): **vocÃª saberÃ¡ que o(s) bug(s) foi(ram) corrigido(s) quando todos os testes desse arquivo passarem.**

<details>

<summary> ğŸ¤– Comportamento esperado da funÃ§Ã£o <code>show_deepest_file</code> </summary>

A funÃ§Ã£o `show_deepest_file` deve receber um dicionÃ¡rio `context` com a chave `all_files` e imprime na saÃ­da padrÃ£o (`stdout`) o caminho do arquivo mais profundo dentro do diretÃ³rio informado. A chave `all_files` armazena uma lista de strings, que representam os caminhos de todos os arquivos dentro de um diretÃ³rio.

**O caminho mais profundo** serÃ¡ o caminho que possui a maior quantidade de diretÃ³rios aninhados. Considere esse exemplo:

```python
context = {
    "all_files": [
        "/home/trybe/Downloads/trybe_logo.png",
        "/home/trybe/Documents/aula/python/tests.txt",
    ]
}

show_deepest_file(context)
# SaÃ­da:
# Deepest file: /home/trybe/Documents/aula/python/tests.txt

context = {
    "all_files": []
}

show_deepest_file(context)
# SaÃ­da:
# No files found
```

Na primeira chamada, o arquivo com caminho mais profundo Ã© `/home/trybe/Documents/aula/python/tests.txt`, pois ele possui 5 diretÃ³rios aninhados: `home`, `trybe` e `Documents`, `aula` e `python`.

Na segunda chamada, nÃ£o hÃ¡ arquivos dentro do diretÃ³rio informado, entÃ£o a funÃ§Ã£o imprime `No files found`.

> **De olho na dica ğŸ‘€:** Essa funÃ§Ã£o pode ser acionada pelo comando `pro-filer <caminho> deepest-file`!

</details>

<details>

<summary> ğŸ“Œ O que serÃ¡ testado </summary>

- A funÃ§Ã£o `show_deepest_file` deve imprimir, na saÃ­da padrÃ£o (`stdout`), o caminho do arquivo mais profundo dentro do diretÃ³rio informado;
- A funÃ§Ã£o `show_deepest_file` deve imprimir, na saÃ­da padrÃ£o (`stdout`), `No files found` caso nÃ£o haja arquivos listados no dicionÃ¡rio `context`;
- Todos os testes do arquivo `tests/actions/test_deepest_file.py` devem passar.

</details>

### 2. Elimine o(s) bug(s) da funÃ§Ã£o `find_file_by_name`

> Arquivo a ser alterado: `pro_filer/actions/beta_actions.py`

Com a resoluÃ§Ã£o do Ãºltimo bug, as pessoas responsÃ¡veis pela manutenÃ§Ã£o do projeto ficaram extremamente satisfeitas e agora estÃ£o solicitando uma nova tarefa para vocÃª!

Encontre e corrija o(s) bug(s) da funÃ§Ã£o `find_file_by_name` para que ela faÃ§a corretamente a busca de arquivos baseada em um termo de busca.

Execute os testes do arquivo `tests/actions/test_find_file_by_name.py` para te ajudar a encontrar o(s) bug(s): **vocÃª saberÃ¡ que o(s) bug(s) foi(ram) corrigido(s) quando todos os testes desse arquivo passarem.**
<details>

<summary> ğŸ¤– Comportamento esperado da funÃ§Ã£o <code>find_file_by_name</code> </summary>

A funÃ§Ã£o `find_file_by_name` deve receber como parÃ¢metro:

- um dicionÃ¡rio `context` com a chave `all_files`, que armazena uma lista de strings, representando os caminhos de todos os arquivos dentro de um diretÃ³rio
- uma _string_ `search_term` com a string a ser buscada
- (opcional) um _booleano_ `case_sensitive` que indica se a busca deve ser sensÃ­vel a maiÃºsculas e minÃºsculas ou nÃ£o. O valor padrÃ£o Ã© `True`.

O retorno serÃ¡ uma lista de strings com os caminhos dos arquivos que possuem o termo buscado em seu nome.

**A busca Ã© realizada** considerando apenas o nome do arquivo (com sua extensÃ£o), ignorando o nome das pastas. Considere esse exemplo:

```python
context = {
    "all_files": [
        "/home/trybe/Downloads/Trybe_logo.png",
        "/home/trybe/Documents/aula/python/tests.py",
    ]
}


find_file_by_name(context, '.py')
# Retorno: ["/home/trybe/Documents/aula/python/tests.py"]

find_file_by_name(context, 'trybe', case_sensitive=False)
# Retorno: ["/home/trybe/Downloads/Trybe_logo.png"]

context = {
    "all_files": []
}

find_file_by_name(context, "trybe")
# Retorno: []
```

Na 1Âª chamada, apenas o segundo arquivo Ã© encontrado pois apenas ele possui o termo `.py` em seu nome.

JÃ¡ na 2Âª chamada, apenas o primeiro arquivo Ã© encontrado, pois apenas ele possui o termo `Trybe` em seu nome. Como `case_sensitive` foi passado como `False`, a busca nÃ£o diferencia maiÃºsculas de minÃºsculas.

E na 3Âª chamada, nÃ£o hÃ¡ arquivos dentro do dicionÃ¡rio `context`, entÃ£o a funÃ§Ã£o retorna uma lista vazia.

> **De olho na dica ğŸ‘€:** Essa funÃ§Ã£o pode ser acionada pelo comando `pro-filer <caminho> search-file <termo_de_busca>`!

</details>

<details>

<summary> ğŸ“Œ O que serÃ¡ testado </summary>

- A funÃ§Ã£o `find_file_by_name` deve retornar uma lista com todos os caminhos de arquivos que possuem o a string `search_term` em seu nome, ignorando o nome das pastas;
- A funÃ§Ã£o `find_file_by_name` deve realizar a busca por arquivos considerando corretamente o parÃ¢metro `case_sensitive`;
- A funÃ§Ã£o `find_file_by_name` deve retornar uma lista vazia caso nÃ£o haja arquivos listados no dicionÃ¡rio `context`;
- Todos os testes do arquivo `tests/actions/test_find_file_by_name.py` devem passar.

</details>

### 3. Crie testes para a funÃ§Ã£o `show_preview`

> Arquivo a ser alterado: `tests/actions/test_show_preview.py`

Agora que vocÃª jÃ¡ corrigiu bugs do projeto e mostrou que consegue trabalhar com o `Pytest`, as pessoas encarregadas do projeto solicitaram que vocÃª desenvolva testes para as funÃ§Ãµes que ainda nÃ£o foram testadas!

Implemente testes para a funÃ§Ã£o `show_preview` do arquivo `pro_filer/actions/main_actions.py` para garantir que ela estÃ¡ funcionando corretamente. **Os testes devem ser implementados no arquivo `tests/actions/test_show_preview.py`. VocÃª pode criar quantas funÃ§Ãµes de teste desejar, desde que respeite o padrÃ£o do `Pytest`.**

<details>

<summary> ğŸ¤– Comportamento esperado da funÃ§Ã£o <code>show_preview</code> </summary>

A funÃ§Ã£o `show_preview` deve receber como parÃ¢metro um dicionÃ¡rio `context` com as chaves `all_files` e `all_dirs`:

- `all_files` armazena uma lista de strings, representando os caminhos de todos os arquivos dentro de um diretÃ³rio;
- `all_dirs` armazena uma lista de strings, representando os caminhos de todos os diretÃ³rios dentro de um diretÃ³rio.

A funÃ§Ã£o imprime na saÃ­da padrÃ£o (`stdout`):

- A quantidade de arquivos e diretÃ³rios listados;
- Se houver algum dado nas chaves do dicionÃ¡rio `context`, os 5 primeiros arquivos listados;
- Se houver algum dado nas chaves do dicionÃ¡rio `context`, os 5 primeiros diretÃ³rios listados.

Considere esse exemplo:

```python
context = {
    "all_files": ["src/__init__.py", "src/app.py", "src/utils/__init__.py"],
    "all_dirs": ["src", "src/utils"]
}


show_preview(context)
# SaÃ­da:
# Found 3 files and 2 directories
# First 5 files: ['src/__init__.py', 'src/app.py', 'src/utils/__init__.py']
# First 5 directories: ['src', 'src/utils']


context = {
    "all_files": [],
    "all_dirs": []
}


show_preview(context)
# SaÃ­da:
# Found 0 files and 0 directories
```

Na 1 primeira chamada, a funÃ§Ã£o imprime as informaÃ§Ãµes como.

Na 2Âª chamada, nÃ£o hÃ¡ arquivos listados em `all_files`, entÃ£o a funÃ§Ã£o imprime apenas o espaÃ§o total ocupado: `0`.

> **De olho na dica ğŸ‘€:** Essa funÃ§Ã£o pode ser acionada pelo comando `pro-filer <caminho> preview`!

> **De olho na dica ğŸ‘€:** Execute o teste da Trybe `tests/trybe/show_preview_test.py` para verificar se seus testes cobrem todos os casos de uso previstos!

</details>

<details>

<summary> ğŸ“Œ O que serÃ¡ testado </summary>

- Os seus testes rejeitam implementaÃ§Ãµes de `show_preview` que consideram apenas `all_files` e `all_dirs` vazios;
- Os seus testes rejeitam implementaÃ§Ãµes de `show_preview` que exibem mais do que 5 arquivos e/ou diretÃ³rios;
- Os seus testes aprovam a implementaÃ§Ã£o de `show_preview` presente em `pro_filer/actions/main_actions.py`.

</details>

<details>
  <summary> ğŸ“Œ Como seu teste Ã© avaliado </summary>

O **teste da Trybe** irÃ¡ avaliar se os **seus testes** estÃ£o passando conforme seu objetivo, e se estÃ£o falhando em alguns casos que deveria falhar.

Executaremos as funÃ§Ãµes de teste que vocÃª escrever no arquivo indicado (`tests/actions/test_show_preview.py`) substituindo a funÃ§Ã£o sendo testada (`show_preview`) por outras implementaÃ§Ãµes "quebradas".

âŒ Se seu teste **aprovar** alguma das implementaÃ§Ãµes "quebradas", **o teste da Trybe FALHARÃ**, indicando que o requisito **nÃ£o estÃ¡** aprovado.

âœ… Se seu teste **rejeitar** todas as implementaÃ§Ãµes "quebradas", **o teste da Trybe PASSARÃ**, indicando que o requisito **estÃ¡** aprovado.

</details>

### 4. Crie testes para a funÃ§Ã£o `show_details`

> Arquivo a ser alterado: `tests/actions/test_show_details.py`

ParabÃ©ns por todas as contribuiÃ§Ãµes feitas atÃ© aqui! O time responsÃ¡vel pelo projeto estÃ¡ gostando do seu trabalho e tem uma nova tarefa para vocÃª: criar testes para outra funcionalidade!

Implemente testes para a funÃ§Ã£o `show_details` do arquivo `pro_filer/actions/main_actions.py` para garantir que ela estÃ¡ funcionando corretamente. **Os testes devem ser implementados no arquivo `tests/actions/test_show_details.py`. VocÃª pode criar quantas funÃ§Ãµes de teste desejar, desde que respeite o padrÃ£o do `Pytest`.**

<details>

<summary> ğŸ¤– Comportamento esperado da funÃ§Ã£o <code>show_details</code> </summary>

A funÃ§Ã£o `show_details` deve receber como parÃ¢metro um dicionÃ¡rio `context` com as chave `base_path`, que armazena uma string representando o caminho do arquivo (ou diretÃ³rio) que deve ser analisado. A funÃ§Ã£o entÃ£o imprime na saÃ­da padrÃ£o (`stdout`) as seguintes informaÃ§Ãµes:

- O nome do arquivo informado;
- O tamanho ocupado pelo arquivo informado;
- O tipo do arquivo informado (`file` ou `directory`);
- A extensÃ£o do arquivo informado (ou `[no extension]` caso nÃ£o possua extensÃ£o);
- A data da Ãºltima modificaÃ§Ã£o do arquivo informado, no formato `yyyy-mm-dd`.

```python
context = {
    "base_path": "/home/trybe/Downloads/Trybe_logo.png"
}


show_details(context)
# SaÃ­da:
# File name: Trybe_logo.png
# File size in bytes: 22438
# File type: file
# File extension: .png
# Last modified date: 2023-06-13


context = {
    "base_path": "/home/trybe/????"
}


show_details(context)
# SaÃ­da:
# File '????' does not exist
```

Na 1Âª chamada, o arquivo Ã© um arquivo comum, entÃ£o a funÃ§Ã£o imprime `file` como tipo do arquivo e `.png` como extensÃ£o.

Na 2Âª chamada, o arquivo informado nÃ£o existe, entÃ£o a funÃ§Ã£o imprime `File '????' does not exist`.

> **De olho na dica ğŸ‘€:** Essa funÃ§Ã£o pode ser acionada pelo comando `pro-filer <caminho> file-details`!

> **De olho na dica ğŸ‘€:** Execute o teste da Trybe `tests/trybe/show_details_test.py` para verificar se seus testes cobrem todos os casos de uso previstos!

</details>

<details>

<summary> ğŸ“Œ O que serÃ¡ testado </summary>

- Os seus testes rejeitam implementaÃ§Ãµes de `show_details` que nÃ£o utilizam as mensagens corretas para exibir cada informaÃ§Ã£o;
- Os seus testes rejeitam implementaÃ§Ãµes de `show_details` que utilizam o formato de data incorreto;
- Os seus testes rejeitam implementaÃ§Ãµes de `show_details` que nÃ£o tratam corretamente o caso de o arquivo informado nÃ£o existir;
- Os seus testes rejeitam implementaÃ§Ãµes de `show_details` que nÃ£o tratam corretamente o caso de o arquivo nÃ£o possuir extensÃ£o;
- Os seus testes aprovam a implementaÃ§Ã£o de `show_details` presente em `pro_filer/actions/main_actions.py`.

</details>

<details>
  <summary> ğŸ“Œ Como seu teste Ã© avaliado </summary>

O **teste da Trybe** irÃ¡ avaliar se os **seus testes** estÃ£o passando conforme seu objetivo, e se estÃ£o falhando em alguns casos que deveria falhar.

Executaremos as funÃ§Ãµes de teste que vocÃª escrever no arquivo indicado (`tests/actions/test_show_details.py`) substituindo a funÃ§Ã£o sendo testada (`show_details`) por outras implementaÃ§Ãµes "quebradas".

âŒ Se seu teste **aprovar** alguma das implementaÃ§Ãµes "quebradas", **o teste da Trybe FALHARÃ**, indicando que o requisito **nÃ£o estÃ¡** aprovado.

âœ… Se seu teste **rejeitar** todas as implementaÃ§Ãµes "quebradas", **o teste da Trybe PASSARÃ**, indicando que o requisito **estÃ¡** aprovado.

</details>

### 5. Crie testes para a funÃ§Ã£o `show_disk_usage`

> Arquivo a ser alterado: `tests/actions/test_show_disk_usage.py`

Continuando suas contribuiÃ§Ãµes no projeto, precisamos que vocÃª crie testes para mais uma funcionalidade importante do projeto!

Implemente testes para a funÃ§Ã£o `show_disk_usage` do arquivo `pro_filer/actions/main_actions.py` para garantir que ela estÃ¡ funcionando corretamente. **Os testes devem ser implementados no arquivo `tests/actions/test_show_disk_usage.py`. VocÃª pode criar quantas funÃ§Ãµes de teste desejar, desde que respeite o padrÃ£o do `Pytest`.**

<details>

<summary> ğŸ¤– Comportamento esperado da funÃ§Ã£o <code>show_disk_usage</code> </summary>

A funÃ§Ã£o `show_disk_usage` deve receber como parÃ¢metro um dicionÃ¡rio `context` com a chave `all_files`, que armazena uma lista de strings representando os caminhos de todos os arquivos dentro de um diretÃ³rio. A funÃ§Ã£o entÃ£o imprime na saÃ­da padrÃ£o (`stdout`) o espaÃ§o total ocupado por todos os arquivos dentro do diretÃ³rio informado.

A funÃ§Ã£o entÃ£o imprime na saÃ­da padrÃ£o (`stdout`) as seguintes informaÃ§Ãµes:

- Para cada arquivo listado em `all_files`:
  - O caminho do arquivo;
  - O espaÃ§o ocupado pelo arquivo, em bytes;
  - A porcentagem do tamanho ocupado pelo arquivo em relaÃ§Ã£o ao espaÃ§o total ocupado (por todos os arquivos listados em `all_files`);
- O espaÃ§o total ocupado por todos os arquivos listados em `all_files`, em bytes.

**A listagem de arquivos** Ã© realizada em ordem decrescente de espaÃ§o ocupado. Considere esse exemplo:

```python
context = {
    "all_files": [
        "src/app.py",
        "src/__init__.py",
    ]
}


show_disk_usage(context)
# SaÃ­da:
# 'src/app.py':                                                          2849 (100%)
# 'src/__init__.py':                                                     0 (0%)
# Total size: 2849

context = {
    "all_files": []
}


show_disk_usage(context)
# SaÃ­da:
# Total size: 0
```

Na 1 primeira chamada, a funÃ§Ã£o imprime a listagem de arquivos e seu tamanho em _bytes_ com a porcentagem do total e, ao final, o espaÃ§o total ocupado pelos arquivos listados.

Na 2Âª chamada, nÃ£o hÃ¡ arquivos listados em `all_files`, entÃ£o a funÃ§Ã£o imprime apenas o espaÃ§o total ocupado: `0`.

**AtenÃ§Ã£o âš ï¸:** Como pode ser observado na implementaÃ§Ã£o de `show_disk_usage`, a formataÃ§Ã£o de cada linha da listagem de arquivos Ã© feita com auxÃ­lio da funÃ§Ã£o `_get_printable_file_path`. NÃ£o se preocupe em validar o comportamento dessa funÃ§Ã£o, vocÃª pode criar um dublÃª de teste para ela.

> **De olho na dica ğŸ‘€:** Essa funÃ§Ã£o pode ser acionada pelo comando `pro-filer <caminho> disk-usage`!

> **De olho na dica ğŸ‘€:** Execute o teste da Trybe `tests/trybe/show_disk_usage_test.py` para verificar se seus testes cobrem todos os casos de uso previstos!

</details>

<details>

<summary> ğŸ“Œ O que serÃ¡ testado </summary>

- Os seus testes rejeitam implementaÃ§Ãµes de `show_disk_usage` que nÃ£o calculam corretamente o espaÃ§o total ocupado pelos arquivos listados em `all_files`;
- Os seus testes rejeitam implementaÃ§Ãµes de `show_disk_usage` que consideram todos os arquivos como vazios;
- Os seus testes rejeitam implementaÃ§Ãµes de `show_disk_usage` que nÃ£o ordenam corretamente a listagem de arquivos;
- Os seus testes aprovam a implementaÃ§Ã£o de `show_disk_usage` presente em `pro_filer/actions/main_actions.py`;
- Os seus testes utilizam a fixture `tmp_path` para criar arquivos temporÃ¡rios.

</details>

<details>
  <summary> ğŸ“Œ Como seu teste Ã© avaliado </summary>

O **teste da Trybe** irÃ¡ avaliar se os **seus testes** estÃ£o passando conforme seu objetivo, e se estÃ£o falhando em alguns casos que deveria falhar.

Executaremos as funÃ§Ãµes de teste que vocÃª escrever no arquivo indicado (`tests/actions/test_show_disk_usage.py`) substituindo a funÃ§Ã£o sendo testada (`show_disk_usage`) por outras implementaÃ§Ãµes "quebradas".

âŒ Se seu teste **aprovar** alguma das implementaÃ§Ãµes "quebradas", **o teste da Trybe FALHARÃ**, indicando que o requisito **nÃ£o estÃ¡** aprovado.

âœ… Se seu teste **rejeitar** todas as implementaÃ§Ãµes "quebradas", **o teste da Trybe PASSARÃ**, indicando que o requisito **estÃ¡** aprovado.

</details>

### 6. Crie testes para a funÃ§Ã£o `find_duplicate_files`

> Arquivo a ser alterado: `tests/actions/test_find_duplicate_files.py`

Para concluir sua participaÃ§Ã£o na temporada de melhorias, as pessoas responsÃ¡veis pelo projeto tÃªm uma Ãºltima tarefa para vocÃª: criar testes para uma funcionalidade final!

Implemente testes para a funÃ§Ã£o `find_duplicate_files` do arquivo `pro_filer/actions/main_actions.py` para garantir que ela estÃ¡ funcionando corretamente. **Os testes devem ser implementados no arquivo `tests/actions/test_find_duplicate_files.py`. VocÃª pode criar quantas funÃ§Ãµes de teste desejar, desde que respeite o padrÃ£o do `Pytest`.**

<details>

<summary> ğŸ¤– Comportamento esperado da funÃ§Ã£o <code>find_duplicate_files</code> </summary>

A funÃ§Ã£o `find_duplicate_files` deve receber como parÃ¢metro um dicionÃ¡rio `context` com a chave `all_files`, que armazena uma lista de strings representando os caminhos de todos os arquivos dentro de um diretÃ³rio.

A funÃ§Ã£o entÃ£o retorna uma lista de tuplas com os pares de arquivos que possuem o mesmo conteÃºdo.

Considere esse exemplo:

```python
context = {
    "all_files": [
        ".gitignore",
        "src/app.py",
        "src/utils/__init__.py",
    ]
}


find_duplicate_files(context)
# Retorno:
# []

context = {
    "all_files": [
        "./tests/__init__.py",
        "./tests/actions/__init__.py",
        "./pro_filer/__init__.py",
    ]
}

find_duplicate_files(context)
# Retorno:
# [
#     ('./tests/__init__.py', './tests/actions/__init__.py'),
#     ('./tests/__init__.py', './pro_filer/__init__.py'),
#     ('./tests/actions/__init__.py', './pro_filer/__init__.py')
# ]
```

Na 1 primeira chamada, o resultado Ã© uma lista vazia pois nÃ£o hÃ¡ arquivos duplicados: todos os arquivos possuem conteÃºdos diferentes.

Na 2Âª chamada, o resultado Ã© uma lista de tuplas com todos os pares de arquivos duplicados. Como todos os arquivos possuem o mesmo conteÃºdo, todos os pares sÃ£o retornados.

> **AtenÃ§Ã£o âš ï¸:** Como pode ser observado na implementaÃ§Ã£o de `find_duplicate_files`, a comparaÃ§Ã£o de conteÃºdo de arquivos Ã© feita com auxÃ­lio da funÃ§Ã£o `filecmp.cmp(...)`. Essa funÃ§Ã£o Ã© nativa do Python, e compara o conteÃºdo dos arquivos (retornando `True` se forem iguais). Caso algum dos arquivos nÃ£o exista, Ã© levantada uma exceÃ§Ã£o `FileNotFoundError`.

Caso a exceÃ§Ã£o `FileNotFoundError` seja levantada na chamada de `filecmp.cmp(...)`, a funÃ§Ã£o `find_duplicate_files` levantarÃ¡ uma exceÃ§Ã£o `ValueError`. VocÃª deve testar se a exceÃ§Ã£o `ValueError` Ã© levantada caso algum arquivo em `all_files` nÃ£o exista.

> **De olho na dica ğŸ‘€:** Essa funÃ§Ã£o pode ser acionada pelo comando `pro-filer <caminho> find-duplicate`!

> **De olho na dica ğŸ‘€:** Execute o teste da Trybe `tests/trybe/find_duplicate_test.py` para verificar se seus testes cobrem todos os casos de uso previstos!

</details>

<details>

<summary> ğŸ“Œ O que serÃ¡ testado </summary>

- Os seus testes rejeitam implementaÃ§Ãµes de `find_duplicate_files` que consideram todos os arquivos em `all_files` como diferentes;
- Os seus testes rejeitam implementaÃ§Ãµes de `find_duplicate_files` que consideram todos os arquivos em `all_files` como iguais;
- Os seus testes rejeitam implementaÃ§Ãµes de `find_duplicate_files` que nÃ£o levanta `ValueError` caso algum arquivo em `all_files` nÃ£o exista;
- Os seus testes aprovam a implementaÃ§Ã£o de `find_duplicate_files` presente em `pro_filer/actions/main_actions.py`;
- Os seus testes utilizam a fixture `tmp_path` para criar arquivos temporÃ¡rios.

</details>

<details>
  <summary> ğŸ“Œ Como seu teste Ã© avaliado </summary>

O **teste da Trybe** irÃ¡ avaliar se os **seus testes** estÃ£o passando conforme seu objetivo, e se estÃ£o falhando em alguns casos que deveria falhar.

Executaremos as funÃ§Ãµes de teste que vocÃª escrever no arquivo indicado (`tests/actions/test_show_disk_usage.py`) substituindo a funÃ§Ã£o sendo testada (`show_disk_usage`) por outras implementaÃ§Ãµes "quebradas".

âŒ Se seu teste **aprovar** alguma das implementaÃ§Ãµes "quebradas", **o teste da Trybe FALHARÃ**, indicando que o requisito **nÃ£o estÃ¡** aprovado.

âœ… Se seu teste **rejeitar** todas as implementaÃ§Ãµes "quebradas", **o teste da Trybe PASSARÃ**, indicando que o requisito **estÃ¡** aprovado.

</details>

---

<!-- mdi versÃ£o 1.0 projeto python âš ï¸ nÃ£o exclua esse comentÃ¡rio -->
